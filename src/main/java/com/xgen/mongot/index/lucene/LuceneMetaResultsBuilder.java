package com.xgen.mongot.index.lucene;

import static com.xgen.mongot.util.Check.checkState;
import static java.lang.String.format;

import com.google.errorprone.annotations.Var;
import com.xgen.mongot.index.FacetBucket;
import com.xgen.mongot.index.FacetInfo;
import com.xgen.mongot.index.MetaResults;
import com.xgen.mongot.index.definition.FieldTypeDefinition;
import com.xgen.mongot.index.lucene.explain.explainers.FacetFeatureExplainer;
import com.xgen.mongot.index.lucene.explain.timing.ExplainTimings;
import com.xgen.mongot.index.lucene.facet.TokenFacetsStateCache;
import com.xgen.mongot.index.lucene.facet.TokenSsdvFacetState;
import com.xgen.mongot.index.lucene.field.FieldName;
import com.xgen.mongot.index.lucene.searcher.LuceneIndexSearcher;
import com.xgen.mongot.index.query.CollectorQuery;
import com.xgen.mongot.index.query.InvalidQueryException;
import com.xgen.mongot.index.query.ReturnScope;
import com.xgen.mongot.index.query.collectors.FacetCollector;
import com.xgen.mongot.index.query.collectors.FacetDefinition;
import com.xgen.mongot.index.query.counts.Count;
import com.xgen.mongot.util.CheckedStream;
import com.xgen.mongot.util.CollectionUtils;
import com.xgen.mongot.util.FieldPath;
import com.xgen.mongot.util.concurrent.NamedExecutorService;
import com.xgen.mongot.util.timers.InvocationCountingTimer;
import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.function.Function;
import java.util.stream.Collectors;
import java.util.stream.Stream;
import org.apache.lucene.facet.DrillSideways.DrillSidewaysResult;
import org.apache.lucene.facet.FacetResult;
import org.apache.lucene.facet.Facets;
import org.apache.lucene.facet.FacetsCollector;
import org.apache.lucene.facet.sortedset.ConcurrentSortedSetDocValuesFacetCounts;
import org.apache.lucene.facet.sortedset.SortedSetDocValuesFacetCounts;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.TotalHits;
import org.bson.BsonString;

/**
 * Holds the logic for building {@link MetaResults} from the artifacts generated by a lucene search.
 */
class LuceneMetaResultsBuilder {

  private final LuceneFacetContext facetContext;
  private final Optional<NamedExecutorService> concurrentSearchExecutor;

  public LuceneMetaResultsBuilder(
      LuceneFacetContext facetContext, Optional<NamedExecutorService> concurrentSearchExecutor) {
    this.facetContext = facetContext;
    this.concurrentSearchExecutor = concurrentSearchExecutor;
  }

  public MetaResults getCountMetaResults(TopDocs topDocs, Count.Type countType) {
    return new MetaResults(LuceneFacetResultUtil.getCount(topDocs.totalHits.value, countType));
  }

  public MetaResults buildFacetMetaResults(
      LuceneIndexSearcherReference searcherReference,
      TopDocs topDocs,
      FacetsCollector collector,
      CollectorQuery collectorQuery,
      boolean concurrentSearch)
      throws IOException, InterruptedException, InvalidQueryException {

    // Ensure that we have an exact count.
    checkState(
        topDocs.totalHits.relation == TotalHits.Relation.EQUAL_TO,
        "FacetsCollector did not provide an exact count");
    var totalCount = topDocs.totalHits.value;
    var returnScopePath = collectorQuery.returnScope().map(ReturnScope::path);
    return switch (collectorQuery.collector()) {
      case FacetCollector facetCollector -> {
        Map<FacetDefinition.Type, Map<String, FacetDefinition>> typeToFacetToDefinition =
            facetCollector.getFacetDefinitionsByType();

        Map<String, FacetInfo> facets =
            Stream.of(
                    getStringFacetResult(
                        searcherReference,
                        typeToFacetToDefinition.get(FacetDefinition.Type.STRING),
                        collector,
                        returnScopePath,
                        concurrentSearch),
                    getBoundaryFacetResults(
                        typeToFacetToDefinition.get(FacetDefinition.Type.NUMBER),
                        collector,
                        this.facetContext,
                        totalCount,
                        returnScopePath),
                    getBoundaryFacetResults(
                        typeToFacetToDefinition.get(FacetDefinition.Type.DATE),
                        collector,
                        this.facetContext,
                        totalCount,
                        returnScopePath))
                .flatMap(map -> map.entrySet().stream())
                .collect(CollectionUtils.toMapUnsafe(Map.Entry::getKey, Map.Entry::getValue));

        yield new MetaResults(
            LuceneFacetResultUtil.getCount(topDocs.totalHits.value, collectorQuery.count().type()),
            Optional.of(facets));
      }
    };
  }

  public MetaResults buildDrillSidewaysFacetMetaResults(
      LuceneIndexSearcherReference searcherReference,
      TopDocs topDocs,
      CollectorQuery collectorQuery,
      Function<String, Optional<DrillSidewaysResult>> facetToDrillSidewaysResultsConverter)
      throws IOException, InvalidQueryException {
    // Ensure that we have an exact count.
    checkState(
        topDocs.totalHits.relation == TotalHits.Relation.EQUAL_TO,
        "FacetsCollector did not provide an exact count");
    var totalCount = topDocs.totalHits.value;
    return switch (collectorQuery.collector()) {
      case FacetCollector facetCollector -> {
        Map<FacetDefinition.Type, Map<String, FacetDefinition>> typeToFacetToDefinition =
            facetCollector.getFacetDefinitionsByType();
        Optional<FieldPath> returnScope = collectorQuery.returnScope().map(ReturnScope::path);
        Map<String, FacetInfo> facets =
            CheckedStream.from(
                    Stream.of(
                            getDrillSidewaysStringFacetResult(
                                searcherReference,
                                typeToFacetToDefinition.get(FacetDefinition.Type.STRING),
                                returnScope,
                                facetToDrillSidewaysResultsConverter),
                            getDrillSidewaysBoundaryFacetResults(
                                typeToFacetToDefinition.get(FacetDefinition.Type.NUMBER),
                                this.facetContext,
                                totalCount,
                                returnScope,
                                facetToDrillSidewaysResultsConverter),
                            getDrillSidewaysBoundaryFacetResults(
                                typeToFacetToDefinition.get(FacetDefinition.Type.DATE),
                                this.facetContext,
                                totalCount,
                                returnScope,
                                facetToDrillSidewaysResultsConverter))
                        .flatMap(map -> map.entrySet().stream()))
                .collectToMapChecked(
                    Map.Entry::getKey,
                    Map.Entry::getValue,
                    (v1, v2) -> {
                      throw new InvalidQueryException(
                          format("Found multiple facets with same name : %s and %s", v1, v2));
                    });
        yield new MetaResults(
            LuceneFacetResultUtil.getCount(topDocs.totalHits.value, collectorQuery.count().type()),
            Optional.of(facets));
      }
    };
  }

  private Map<String, FacetInfo> getBoundaryFacetResults(
      Map<String, FacetDefinition> facetToDefinition,
      FacetsCollector collector,
      LuceneFacetContext facetContext,
      long totalCount,
      Optional<FieldPath> returnScope)
      throws IOException, InvalidQueryException {
    Map<String, FacetInfo> resultMap = new HashMap<>();
    for (Map.Entry<String, FacetDefinition> entry : facetToDefinition.entrySet()) {
      String key = entry.getKey();
      FacetInfo facetInfo =
          getBoundaryFacetResult(
              entry.getValue(), collector, facetContext, totalCount, returnScope);

      resultMap.put(key, facetInfo);
    }
    return resultMap;
  }

  private FacetInfo getBoundaryFacetResult(
      FacetDefinition facetDefinition,
      DrillSidewaysResult drillSidewaysResult,
      LuceneFacetContext facetContext,
      long totalCount,
      Optional<FieldPath> returnScope)
      throws IOException, InvalidQueryException {
    var boundaryDefinition = (FacetDefinition.BoundaryFacetDefinition<?>) facetDefinition;
    String path = facetContext.getBoundaryFacetPath(boundaryDefinition, returnScope);
    FacetResult facetResult = drillSidewaysResult.facets.getAllChildren(path);
    List<FacetBucket> results = new ArrayList<>();
    @Var long facetDocsCount = 0;
    for (int i = 0; i < facetResult.labelValues.length; i++) {
      long bucketCount = facetResult.labelValues[i].value.longValue();
      if (bucketCount > 0) {
        facetDocsCount += bucketCount;
        results.add(new FacetBucket(boundaryDefinition.boundaries().get(i), bucketCount));
      }
    }

    if (boundaryDefinition.defaultBucketName().isPresent()) {
      // Default bucket can be computed by subtracting the total docs in the buckets from the
      // total docs returned by the query, which is accurate when provided by the FacetsCollector.
      // This also relies on the fact that we do not index numbers or dates in arrays.
      results.add(
          new FacetBucket(
              new BsonString(boundaryDefinition.defaultBucketName().get()),
              totalCount - facetDocsCount));
    }

    return new FacetInfo(results);
  }

  private FacetInfo getBoundaryFacetResult(
      FacetDefinition facetDefinition,
      FacetsCollector facetsCollector,
      LuceneFacetContext facetContext,
      long totalCount,
      Optional<FieldPath> returnScope)
      throws IOException, InvalidQueryException {
    var boundaryDefinition = (FacetDefinition.BoundaryFacetDefinition<?>) facetDefinition;
    FacetResult facetResult =
        LuceneFacetResultUtil.getBoundaryFacetResult(
            boundaryDefinition, facetContext, facetsCollector, returnScope);
    List<FacetBucket> results = new ArrayList<>();
    @Var long facetDocsCount = 0;
    for (int i = 0; i < facetResult.labelValues.length; i++) {
      long bucketCount = facetResult.labelValues[i].value.longValue();
      facetDocsCount += bucketCount;
      results.add(new FacetBucket(boundaryDefinition.boundaries().get(i), bucketCount));
    }

    if (boundaryDefinition.defaultBucketName().isPresent()) {
      // Default bucket can be computed by subtracting the total docs in the buckets from the
      // total docs returned by the query, which is accurate when provided by the FacetsCollector.
      // This also relies on the fact that we do not index numbers or dates in arrays.
      results.add(
          new FacetBucket(
              new BsonString(boundaryDefinition.defaultBucketName().get()),
              totalCount - facetDocsCount));
    }

    return new FacetInfo(results);
  }

  private Map<String, FacetInfo> getDrillSidewaysStringFacetResult(
      LuceneIndexSearcherReference searcherReference,
      Map<String, FacetDefinition> stringFacetToDefinition,
      Optional<FieldPath> returnScope,
      Function<String, Optional<DrillSidewaysResult>> facetToDrillSidewaysResultsConverter)
      throws IOException, InvalidQueryException {

    var searcher = searcherReference.getIndexSearcher();
    if (stringFacetToDefinition.isEmpty()) {
      return Map.of();
    }
    Map<FieldTypeDefinition.Type, Map<String, FacetDefinition.StringFacetDefinition>>
        facetableStringTypeToNameToDefinition =
            LuceneFacetResultUtil.groupFacetableStringDefinitions(
                this.facetContext, stringFacetToDefinition, returnScope);

    return Stream.of(
            getStringFacetFieldDrillSidewaysResults(
                facetableStringTypeToNameToDefinition.get(FieldTypeDefinition.Type.STRING_FACET),
                facetToDrillSidewaysResultsConverter,
                searcher),
            getTokenFieldDrillSidewaysResults(
                facetableStringTypeToNameToDefinition.get(FieldTypeDefinition.Type.TOKEN),
                returnScope,
                facetToDrillSidewaysResultsConverter,
                searcher))
        .flatMap(map -> map.entrySet().stream())
        .collect(
            Collectors.toMap(
                Map.Entry::getKey,
                Map.Entry::getValue,
                (facetInfo1, facetInfo2) -> {
                  if (!facetInfo1.buckets().isEmpty() && !facetInfo2.buckets().isEmpty()) {
                    throw new IllegalStateException(
                        String.format(
                            "Facet has different facet infos as string and token types - %s and %s",
                            facetInfo1, facetInfo2));
                  }
                  return facetInfo1.buckets().isEmpty() ? facetInfo2 : facetInfo1;
                }));
  }

  private Map<String, FacetInfo> getTokenFieldDrillSidewaysResults(
      Map<String, FacetDefinition.StringFacetDefinition> stringFacetToDefinition,
      Optional<FieldPath> returnScope,
      Function<String, Optional<DrillSidewaysResult>> facetToDrillSidewaysResultsConverter,
      LuceneIndexSearcher searcher)
      throws IOException, InvalidQueryException {

    // Should still report facet categories with a count of 0 if no facets have been indexed.
    if (searcher.getTokenFacetsStateCache().isEmpty()) {
      return CollectionUtils.newMapFromKeys(
          stringFacetToDefinition, (ignored1, ignored2) -> new FacetInfo(List.of()));
    }

    Map<String, FacetInfo> result = new HashMap<>();
    TokenFacetsStateCache facetsState = searcher.getTokenFacetsStateCache().get();
    Optional<FacetFeatureExplainer> explainer = LuceneFacetResultUtil.getFacetFeatureExplainer();
    for (var entry : stringFacetToDefinition.entrySet()) {

      FacetDefinition.StringFacetDefinition facetDefinition = entry.getValue();
      String path = facetDefinition.path();
      String lucenePath =
          FieldName.TypeField.TOKEN.getLuceneFieldName(FieldPath.parse(path), returnScope);
      Optional<TokenSsdvFacetState> fieldState = facetsState.get(lucenePath);
      explainer.ifPresent(
          exp ->
              exp.addTotalStringFacetCardinalities(
                  entry.getKey(), fieldState.map(state -> state.getOrdRange(lucenePath))));

      Optional<DrillSidewaysResult> drillSidewaysResult =
          facetToDrillSidewaysResultsConverter.apply(entry.getKey());
      if (drillSidewaysResult.isEmpty()) {
        result.put(entry.getKey(), new FacetInfo(List.of()));
        continue;
      }
      Facets facetCounts = drillSidewaysResult.get().facets;

      Optional<FacetResult> children =
          Optional.ofNullable(facetCounts.getTopChildren(facetDefinition.numBuckets(), lucenePath));

      // can happen when the dimension was never indexed, hits does not contain facet, etc
      if (children.isEmpty()) {
        result.put(entry.getKey(), new FacetInfo(List.of()));
        continue;
      }
      var buckets =
          Stream.of(children.get().labelValues)
              .map(child -> new FacetBucket(new BsonString(child.label), child.value.longValue()))
              .collect(Collectors.toList());
      result.put(entry.getKey(), new FacetInfo(buckets));
    }

    explainer.ifPresent(
        exp -> exp.addNonIntermediateQueriedStringFacetCardinalities(Map.copyOf(result)));

    return result;
  }

  private Map<String, FacetInfo> getStringFacetFieldDrillSidewaysResults(
      Map<String, FacetDefinition.StringFacetDefinition> stringFacetToDefinition,
      Function<String, Optional<DrillSidewaysResult>> facetToDrillSidewaysResultsConverter,
      LuceneIndexSearcher searcher)
      throws IOException {

    // Should still report facet categories with a count of 0 if no facets have been indexed.
    if (searcher.getFacetsState().isEmpty()) {
      return CollectionUtils.newMapFromKeys(
          stringFacetToDefinition, (ignored1, ignored2) -> new FacetInfo(List.of()));
    }

    Map<String, FacetInfo> result = new HashMap<>();

    var facetsState = searcher.getFacetsState().get();
    Optional<FacetFeatureExplainer> explainer = LuceneFacetResultUtil.getFacetFeatureExplainer();
    for (var entry : stringFacetToDefinition.entrySet()) {
      FacetDefinition.StringFacetDefinition facetDefinition = entry.getValue();
      explainer.ifPresent(
          exp ->
              exp.addTotalStringFacetCardinalities(
                  entry.getKey(),
                  Optional.ofNullable(facetsState.getOrdRange(facetDefinition.path()))));

      String path = facetDefinition.path();

      Optional<DrillSidewaysResult> drillSidewaysResult =
          facetToDrillSidewaysResultsConverter.apply(entry.getKey());
      if (drillSidewaysResult.isEmpty()) {
        result.put(entry.getKey(), new FacetInfo(List.of()));
        continue;
      }
      Facets facetCounts = drillSidewaysResult.get().facets;

      Optional<FacetResult> children =
          Optional.ofNullable(facetCounts.getTopChildren(facetDefinition.numBuckets(), path));

      // can happen when the dimension was never indexed, hits does not contain facet, etc
      if (children.isEmpty()) {
        result.put(entry.getKey(), new FacetInfo(List.of()));
        continue;
      }
      var buckets =
          Stream.of(children.get().labelValues)
              .map(child -> new FacetBucket(new BsonString(child.label), child.value.longValue()))
              .collect(Collectors.toList());
      result.put(entry.getKey(), new FacetInfo(buckets));
    }

    explainer.ifPresent(
        exp -> exp.addNonIntermediateQueriedStringFacetCardinalities(Map.copyOf(result)));

    return result;
  }

  private Map<String, FacetInfo> getDrillSidewaysBoundaryFacetResults(
      Map<String, FacetDefinition> facetToDefinition,
      LuceneFacetContext facetContext,
      long totalCount,
      Optional<FieldPath> returnScope,
      Function<String, Optional<DrillSidewaysResult>> facetToDrillSidewaysResultsConverter)
      throws IOException, InvalidQueryException {
    return CheckedStream.from(
            facetToDefinition.entrySet().stream()
                .filter(
                    entry ->
                        facetToDrillSidewaysResultsConverter.apply(entry.getKey()).isPresent()))
        .<String, FacetInfo, RuntimeException, IOException, InvalidQueryException>
            collectToMapCheckedBiValueException(
                Map.Entry::getKey,
                entry ->
                    getBoundaryFacetResult(
                        entry.getValue(),
                        facetToDrillSidewaysResultsConverter.apply(entry.getKey()).get(),
                        facetContext,
                        totalCount,
                        returnScope));
  }

  private Map<String, FacetInfo> getStringFacetResult(
      LuceneIndexSearcherReference searcherReference,
      Map<String, FacetDefinition> stringFacetDefinitions, // Keyed by facet name.
      FacetsCollector collector,
      Optional<FieldPath> returnScope,
      boolean concurrentQuery)
      throws IOException, InterruptedException, InvalidQueryException {

    var searcher = searcherReference.getIndexSearcher();

    if (stringFacetDefinitions.isEmpty()) {
      return Map.of();
    }
    Optional<FacetFeatureExplainer> explainer = LuceneFacetResultUtil.getFacetFeatureExplainer();

    Map<FieldTypeDefinition.Type, Map<String, FacetDefinition.StringFacetDefinition>>
        facetableStringTypeToNameToDefinition =
            LuceneFacetResultUtil.groupFacetableStringDefinitions(
                this.facetContext, stringFacetDefinitions, returnScope);

    var stringFacetFieldResults =
        getStringFacetFieldResult(
            explainer,
            facetableStringTypeToNameToDefinition.get(FieldTypeDefinition.Type.STRING_FACET),
            searcher,
            collector,
            concurrentQuery);
    var tokenFieldResults =
        getTokenFieldResult(
            explainer,
            facetableStringTypeToNameToDefinition.get(FieldTypeDefinition.Type.TOKEN),
            searcher,
            collector,
            returnScope,
            concurrentQuery);
    var result = new HashMap<>(stringFacetFieldResults);
    result.putAll(tokenFieldResults);
    return result;
  }

  private Map<String, FacetInfo> getStringFacetFieldResult(
      Optional<FacetFeatureExplainer> facetFeatureExplainer,
      Map<String, FacetDefinition.StringFacetDefinition> stringFacetToDefinition,
      LuceneIndexSearcher searcher,
      FacetsCollector collector,
      boolean concurrentQuery)
      throws IOException, InterruptedException {

    var result = new HashMap<String, FacetInfo>();
    Optional<ExplainTimings> facetTimings =
        facetFeatureExplainer.map(FacetFeatureExplainer::getCreateCountTimings);

    // Should still report facet categories with a count of 0 if no facets have been indexed.
    if (searcher.getFacetsState().isEmpty()) {
      return CollectionUtils.newMapFromKeys(
          stringFacetToDefinition, (k, v) -> new FacetInfo(List.of()));
    }
    var facetsState = searcher.getFacetsState().get();
    Facets counts;
    try (var unused =
        new InvocationCountingTimer.AutocloseableOptional<>(
            facetTimings.map(t -> t.split(ExplainTimings.Type.GENERATE_FACET_COUNTS)))) {
      counts =
          concurrentQuery && this.concurrentSearchExecutor.isPresent()
              ? new ConcurrentSortedSetDocValuesFacetCounts(
                  facetsState, collector, this.concurrentSearchExecutor.get())
              : new SortedSetDocValuesFacetCounts(facetsState, collector);
    }

    for (var entry : stringFacetToDefinition.entrySet()) {
      facetFeatureExplainer.ifPresent(
          explainer ->
              explainer.addTotalStringFacetCardinalities(
                  entry.getKey(),
                  Optional.ofNullable(facetsState.getOrdRange(entry.getValue().path()))));
      populateFacetBuckets(
          counts, entry.getKey(), entry.getValue().path(), entry.getValue().numBuckets(), result);
    }

    facetFeatureExplainer.ifPresent(
        explainer ->
            explainer.addNonIntermediateQueriedStringFacetCardinalities(Map.copyOf(result)));

    return result;
  }

  private Map<String, FacetInfo> getTokenFieldResult(
      Optional<FacetFeatureExplainer> facetFeatureExplainer,
      Map<String, FacetDefinition.StringFacetDefinition> stringFacetToDefinition,
      LuceneIndexSearcher searcher,
      FacetsCollector collector,
      Optional<FieldPath> returnScope,
      boolean concurrentQuery)
      throws IOException, InterruptedException, InvalidQueryException {
    var result = new HashMap<String, FacetInfo>();
    Optional<ExplainTimings> facetTimings =
        facetFeatureExplainer.map(FacetFeatureExplainer::getCreateCountTimings);

    if (stringFacetToDefinition.isEmpty()) {
      return Map.of();
    }
    // If cache optional is empty, then FF enabling token facets is not enabled
    if (searcher.getTokenFacetsStateCache().isEmpty()) {
      throw new InvalidQueryException(
          format(
              "Faceting over token fields is not enabled. Facets %s are indexed as tokens."
                  + " Please remove them from this query, or index the fields as stringFacet",
              stringFacetToDefinition.keySet()));
    }

    var tokenFacetsStateCache = searcher.getTokenFacetsStateCache().get();

    for (var entry : stringFacetToDefinition.entrySet()) {
      var lucenePath =
          FieldName.TypeField.TOKEN.getLuceneFieldName(
              FieldPath.parse(entry.getValue().path()), returnScope);
      var fieldState = tokenFacetsStateCache.get(lucenePath);
      facetFeatureExplainer.ifPresent(
          explainer ->
              explainer.addTotalStringFacetCardinalities(
                  entry.getKey(), fieldState.map(state -> state.getOrdRange(lucenePath))));

      if (fieldState.isEmpty()) {
        result.put(entry.getKey(), new FacetInfo(List.of()));
        continue;
      }
      Facets counts;
      try (var unused =
          new InvocationCountingTimer.AutocloseableOptional<>(
              facetTimings.map(t -> t.split(ExplainTimings.Type.GENERATE_FACET_COUNTS)))) {
        counts =
            concurrentQuery && this.concurrentSearchExecutor.isPresent()
                ? new com.xgen.mongot.index.lucene.facet.ConcurrentSortedSetDocValuesFacetCounts(
                    fieldState.get(), collector, this.concurrentSearchExecutor.get())
                : new com.xgen.mongot.index.lucene.facet.SortedSetDocValuesFacetCounts(
                    fieldState.get(), collector);
      }
      FacetDefinition.StringFacetDefinition definition = entry.getValue();
      populateFacetBuckets(counts, entry.getKey(), lucenePath, definition.numBuckets(), result);
    }

    facetFeatureExplainer.ifPresent(
        explainer ->
            explainer.addNonIntermediateQueriedStringFacetCardinalities(Map.copyOf(result)));

    return result;
  }

  private void populateFacetBuckets(
      Facets counts, String facetName, String path, int numBuckets, Map<String, FacetInfo> result)
      throws IOException {
    FacetResult children = counts.getTopChildren(numBuckets, path);
    // can happen when the dimension was never indexed, hits does not contain facet, etc
    if (children == null) {
      result.put(facetName, new FacetInfo(List.of()));
      return;
    }
    var buckets =
        Stream.of(children.labelValues)
            .filter(child -> child.label != null && !child.label.isEmpty())
            .map(child -> new FacetBucket(new BsonString(child.label), child.value.longValue()))
            .collect(Collectors.toList());
    result.put(facetName, new FacetInfo(buckets));
  }
}
